{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":14840328,"sourceType":"datasetVersion","datasetId":9491647}],"dockerImageVersionId":31259,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"e2cc57ab","cell_type":"markdown","source":"# VED: preprocessing → regression baseline → residuals\n\nThis notebook is **adapted to the real VED file structure**, where the dynamic data are stored across many files named like `VED_*_week.csv`.\n\nWhat the notebook does:\n\n1. reads *all* `*_week.csv` files from a directory (e.g., `VED_171101_week.csv`);\n2. builds a **trip-level table** (aggregates time-series data → 1 row per trip);\n3. computes the target **energy_per_km** (by integrating power over time and dividing by distance);\n4. trains a regression model (XGBoost) to predict the “normal” trip energy consumption;\n5. saves the model and computes `residual = actual − predicted`.","metadata":{}},{"id":"efef48f9-3b7a-4178-905d-1864c9a4b999","cell_type":"markdown","source":"Recommended setup: run this notebook on Kaggle.\n\nKaggle dataset link: https://www.kaggle.com/datasets/galievilyas/ved-dataset/data","metadata":{}},{"id":"ac20fe28","cell_type":"markdown","source":"## 0) Imports and configuration","metadata":{}},{"id":"99221c22","cell_type":"code","source":"import os\nfrom pathlib import Path\nimport glob\nimport pandas as pd\nimport numpy as np\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error\nfrom xgboost import XGBRegressor\nimport joblib\n\nRANDOM_STATE = 42\n\n# --------- ПУТИ (поменяй под себя) ----------\nDATA_DIR = Path(\"/kaggle/input/datasets/galievilyas/ved-dataset/VED_DynamicData_Part*/\")   # папка где лежат все VED_*_week.csv\nWEEK_GLOB = \"VED_*_week.csv\"\n\nSTATIC_PHEV_EV_XLSX = Path(\"/kaggle/input/datasets/galievilyas/ved-dataset/VED_Static_Data_PHEV_EV.xlsx\")\nSTATIC_ICE_HEV_XLSX = Path(\"/kaggle/input/datasets/galievilyas/ved-dataset/VED_Static_Data_ICE_HEV.xlsx\")\n\nOUT_DIR = Path(\"outputs\")\nMODEL_DIR = Path(\"models\")\nOUT_DIR.mkdir(parents=True, exist_ok=True)\nMODEL_DIR.mkdir(parents=True, exist_ok=True)\n\n# --------- КОЛОНКИ VED (в твоём CSV они такие) ----------\nCOL_DAYNUM = \"DayNum\"\nCOL_VEHID = \"VehId\"\nCOL_TRIP = \"Trip\"\nCOL_TS_MS = \"Timestamp(ms)\"\nCOL_SPEED = \"Vehicle Speed[km/h]\"\nCOL_FUEL_RATE = \"Fuel Rate[L/hr]\"  # для ICE/HEV\n\n# опциональные (могут быть NaN)\nCOL_AC_KW = \"Air Conditioning Power[kW]\"\nCOL_AC_W = \"Air Conditioning Power[Watts]\"\nCOL_HEATER_W = \"Heater Power[Watts]\"\nCOL_HV_I = \"HV Battery Current[A]\"\nCOL_HV_V = \"HV Battery Voltage[V]\"\n\n# ---- ФИЗИЧЕСКИЕ КОНСТАНТЫ / ДОПУЩЕНИЯ ----\nGASOLINE_KWH_PER_LITER = 8.9  # грубая конверсия L топлива -> kWh энергии (LHV). Можно уточнить, но для baseline ок.\nSPEED_STOP_THRESHOLD = 5.0    # km/h\n\npd.options.display.float_format = lambda x: f\"{x:.4f}\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-14T17:52:32.496776Z","iopub.execute_input":"2026-02-14T17:52:32.497443Z","iopub.status.idle":"2026-02-14T17:52:33.682060Z","shell.execute_reply.started":"2026-02-14T17:52:32.497414Z","shell.execute_reply":"2026-02-14T17:52:33.681474Z"}},"outputs":[],"execution_count":1},{"id":"04647034","cell_type":"markdown","source":"## 1) Reading multiple week files\n\nWe read **all** `VED_*_week.csv` files from `DATA_DIR`. If there are many files and memory is limited, you can process them one by one (as we do below) and accumulate the aggregated results.","metadata":{}},{"id":"39db1ada","cell_type":"code","source":"def list_week_files(data_dir: Path, pattern: str) -> list[Path]:\n    files = sorted([Path(p) for p in glob.glob(str(data_dir / pattern))])\n    if not files:\n        raise FileNotFoundError(f\"No files found: {data_dir}/{pattern}\")\n    return files\n\nweek_files = list_week_files(DATA_DIR, WEEK_GLOB)\nprint(f\"Found {len(week_files)} week files. Example: {week_files[0]}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-14T17:52:36.403077Z","iopub.execute_input":"2026-02-14T17:52:36.403500Z","iopub.status.idle":"2026-02-14T17:52:36.456173Z","shell.execute_reply.started":"2026-02-14T17:52:36.403471Z","shell.execute_reply":"2026-02-14T17:52:36.455380Z"}},"outputs":[{"name":"stdout","text":"Found 54 week files. Example: /kaggle/input/datasets/galievilyas/ved-dataset/VED_DynamicData_Part1/VED_171101_week.csv\n","output_type":"stream"}],"execution_count":2},{"id":"080cf11a","cell_type":"markdown","source":"## 2) Target: `energy_per_km` from VED signals\n\nIn VED, the dynamic files include vehicle speed and (for ICE/HEV) `Fuel Rate[L/hr]`. For EV/PHEV, battery current/voltage may be available.\n\nFor a baseline, we compute:\n\n* fuel power: `P_fuel_kW = FuelRate[L/hr] * 8.9 kWh/L` (since L/hr × kWh/L = kWh/hr = kW)\n* battery power: `P_batt_kW = (V * I) / 1000`\n* HVAC: `AC_kW` or `AC_W/1000`, plus `Heater_W/1000`\n* total power: `P_total_kW = P_fuel_kW + P_batt_kW + HVAC`\n* trip energy: integrate `P_total_kW` over time\n* distance: integrate speed over time\n* `energy_per_km = total_energy_kWh / distance_km`\n\nThis is an approximation (especially for fuel-based power), but it is sufficient for a coursework baseline!\n","metadata":{}},{"id":"ac7d878e","cell_type":"code","source":"def compute_instant_power_kW(df: pd.DataFrame) -> np.ndarray:\n    # Fuel power (kW)\n    if COL_FUEL_RATE in df.columns:\n        fuel = df[COL_FUEL_RATE].astype(float).fillna(0.0).to_numpy()\n    else:\n        fuel = np.zeros(len(df), dtype=float)\n    p_fuel = fuel * GASOLINE_KWH_PER_LITER  # (L/hr)*(kWh/L)=kW\n\n    # Battery power (kW)\n    if (COL_HV_I in df.columns) and (COL_HV_V in df.columns):\n        i = df[COL_HV_I].astype(float).fillna(0.0).to_numpy()\n        v = df[COL_HV_V].astype(float).fillna(0.0).to_numpy()\n        p_batt = (v * i) / 1000.0\n    else:\n        p_batt = np.zeros(len(df), dtype=float)\n\n    # HVAC\n    ac = np.zeros(len(df), dtype=float)\n    if COL_AC_KW in df.columns:\n        ac += df[COL_AC_KW].astype(float).fillna(0.0).to_numpy()\n    elif COL_AC_W in df.columns:\n        ac += df[COL_AC_W].astype(float).fillna(0.0).to_numpy() / 1000.0\n\n    heater = np.zeros(len(df), dtype=float)\n    if COL_HEATER_W in df.columns:\n        heater += df[COL_HEATER_W].astype(float).fillna(0.0).to_numpy() / 1000.0\n\n    p_total = p_fuel + p_batt + ac + heater\n    return p_total\n\ndef integrate_trip_energy_distance(trip_df: pd.DataFrame) -> tuple[float, float, float]:\n    \"\"\"Return (energy_kWh, distance_km, duration_min)\"\"\"\n    trip_df = trip_df.sort_values(COL_TS_MS)\n    t = trip_df[COL_TS_MS].astype(float).to_numpy() / 1000.0  # seconds\n    if len(t) < 2:\n        return 0.0, 0.0, 0.0\n    dt = np.diff(t)\n    dt = np.clip(dt, 0.0, None)\n\n    speed_kmh = trip_df[COL_SPEED].astype(float).fillna(0.0).to_numpy()\n    speed_kms = speed_kmh / 3600.0\n\n    p_kW = compute_instant_power_kW(trip_df)\n\n    # Integrals using left Riemann sum on intervals [i, i+1)\n    energy_kWh = float(np.sum(p_kW[:-1] * (dt / 3600.0)))\n    distance_km = float(np.sum(speed_kms[:-1] * dt))\n    duration_min = float((t[-1] - t[0]) / 60.0)\n    return energy_kWh, distance_km, duration_min\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-14T17:52:40.199192Z","iopub.execute_input":"2026-02-14T17:52:40.199583Z","iopub.status.idle":"2026-02-14T17:52:40.208720Z","shell.execute_reply.started":"2026-02-14T17:52:40.199546Z","shell.execute_reply":"2026-02-14T17:52:40.208026Z"}},"outputs":[],"execution_count":3},{"id":"0f258fcb","cell_type":"markdown","source":"## 3) Trip-level feature aggregation (1 row per trip)\n\nWe aggregate the following features:\n\n* duration, distance\n* `speed_mean` / `speed_var`\n* `accel_mean` / `accel_var` / `accel_p95`\n* `stop_go_ratio`, `idle_time_min`\n\nYou can also add any other available signals (RPM, Load, OAT, etc.)—below I’ll leave an example showing how to extend this easily.","metadata":{}},{"id":"1d7c1175","cell_type":"code","source":"def compute_trip_features(trip_df: pd.DataFrame) -> dict:\n    trip_df = trip_df.sort_values(COL_TS_MS)\n    t = trip_df[COL_TS_MS].astype(float).to_numpy() / 1000.0\n    if len(t) < 2:\n        return {}\n\n    dt = np.diff(t)\n    dt = np.clip(dt, 0.0, None)\n    dt_sum = float(np.sum(dt)) + 1e-12\n\n    speed_kmh = trip_df[COL_SPEED].astype(float).fillna(0.0).to_numpy()\n    speed_ms = speed_kmh * (1000.0 / 3600.0)\n\n    # time-weighted mean/var (weights = dt for intervals, align to speed[:-1])\n    w = dt / dt_sum\n    speed_mean = float(np.sum(speed_kmh[:-1] * w))\n    speed_var = float(np.sum(((speed_kmh[:-1] - speed_mean) ** 2) * w))\n\n    # accel over intervals\n    accel = np.diff(speed_ms) / (dt + 1e-12)\n    accel = np.nan_to_num(accel, nan=0.0, posinf=0.0, neginf=0.0)\n    accel_mean = float(np.sum(accel * w))\n    accel_var = float(np.sum(((accel - accel_mean) ** 2) * w))\n    accel_p95 = float(np.percentile(accel, 95))\n\n    stop_go_ratio = float(np.mean(speed_kmh < SPEED_STOP_THRESHOLD))\n    idle_time_min = float(np.sum(dt[speed_kmh[:-1] < 0.1]) / 60.0)\n\n    # trip-level integrals for target\n    energy_kWh, distance_km, duration_min = integrate_trip_energy_distance(trip_df)\n    if distance_km <= 1e-6:\n        energy_per_km = np.nan\n    else:\n        energy_per_km = energy_kWh / distance_km\n\n    return {\n        \"duration_min\": duration_min,\n        \"distance_km\": distance_km,\n        \"speed_mean\": speed_mean,\n        \"speed_var\": speed_var,\n        \"accel_mean\": accel_mean,\n        \"accel_var\": accel_var,\n        \"accel_p95\": accel_p95,\n        \"stop_go_ratio\": stop_go_ratio,\n        \"idle_time_min\": idle_time_min,\n        \"energy_kWh\": energy_kWh,\n        \"energy_per_km\": energy_per_km,\n    }\n\ndef aggregate_week_file(path: Path) -> pd.DataFrame:\n    df = pd.read_csv(path)\n\n    # создаём стабильный trip_id\n    df[\"trip_id\"] = df[COL_VEHID].astype(str) + \"_\" + df[COL_TRIP].astype(str)\n\n    feats = []\n    for trip_id, g in df.groupby(\"trip_id\", sort=False):\n        f = compute_trip_features(g)\n        if not f:\n            continue\n        f[\"trip_id\"] = trip_id\n        f[\"VehId\"] = int(g[COL_VEHID].iloc[0])\n        f[\"Trip\"] = int(g[COL_TRIP].iloc[0])\n        feats.append(f)\n\n    return pd.DataFrame(feats)\n\n# Прогон на одном файле (проверка)\nsample_trips = aggregate_week_file(week_files[0])\nsample_trips.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-14T17:52:42.796875Z","iopub.execute_input":"2026-02-14T17:52:42.797167Z","iopub.status.idle":"2026-02-14T17:52:45.816501Z","shell.execute_reply.started":"2026-02-14T17:52:42.797143Z","shell.execute_reply":"2026-02-14T17:52:45.815897Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"   duration_min  distance_km  speed_mean  speed_var  accel_mean  accel_var  \\\n0        2.2383       2.0546     55.0759   273.2273     -0.0062     0.8663   \n1        3.9917       2.8922     43.4735   672.6869      0.0220     3.0715   \n2        1.7700       0.8968     30.3990   391.4863     -0.0501     1.4627   \n3        3.8583       3.2690     50.8352    85.0810      0.0016     0.8729   \n4        8.1067       6.3116     46.7144   741.2270      0.0069     0.9453   \n\n   accel_p95  stop_go_ratio  idle_time_min  energy_kWh  energy_per_km  \\\n0     1.7650         0.0584         0.0000      0.0000         0.0000   \n1     3.7731         0.1470         0.6017      0.0000         0.0000   \n2     1.7220         0.1008         0.3750     -0.0632        -0.0704   \n3     1.3222         0.0000         0.0000     -0.0171        -0.0052   \n4     2.0910         0.0600         1.0017      0.0000         0.0000   \n\n   trip_id  VehId  Trip  \n0    8_706      8   706  \n1    8_707      8   707  \n2  10_1558     10  1558  \n3  11_1485     11  1485  \n4  124_755    124   755  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>duration_min</th>\n      <th>distance_km</th>\n      <th>speed_mean</th>\n      <th>speed_var</th>\n      <th>accel_mean</th>\n      <th>accel_var</th>\n      <th>accel_p95</th>\n      <th>stop_go_ratio</th>\n      <th>idle_time_min</th>\n      <th>energy_kWh</th>\n      <th>energy_per_km</th>\n      <th>trip_id</th>\n      <th>VehId</th>\n      <th>Trip</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2.2383</td>\n      <td>2.0546</td>\n      <td>55.0759</td>\n      <td>273.2273</td>\n      <td>-0.0062</td>\n      <td>0.8663</td>\n      <td>1.7650</td>\n      <td>0.0584</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>8_706</td>\n      <td>8</td>\n      <td>706</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3.9917</td>\n      <td>2.8922</td>\n      <td>43.4735</td>\n      <td>672.6869</td>\n      <td>0.0220</td>\n      <td>3.0715</td>\n      <td>3.7731</td>\n      <td>0.1470</td>\n      <td>0.6017</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>8_707</td>\n      <td>8</td>\n      <td>707</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.7700</td>\n      <td>0.8968</td>\n      <td>30.3990</td>\n      <td>391.4863</td>\n      <td>-0.0501</td>\n      <td>1.4627</td>\n      <td>1.7220</td>\n      <td>0.1008</td>\n      <td>0.3750</td>\n      <td>-0.0632</td>\n      <td>-0.0704</td>\n      <td>10_1558</td>\n      <td>10</td>\n      <td>1558</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3.8583</td>\n      <td>3.2690</td>\n      <td>50.8352</td>\n      <td>85.0810</td>\n      <td>0.0016</td>\n      <td>0.8729</td>\n      <td>1.3222</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>-0.0171</td>\n      <td>-0.0052</td>\n      <td>11_1485</td>\n      <td>11</td>\n      <td>1485</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>8.1067</td>\n      <td>6.3116</td>\n      <td>46.7144</td>\n      <td>741.2270</td>\n      <td>0.0069</td>\n      <td>0.9453</td>\n      <td>2.0910</td>\n      <td>0.0600</td>\n      <td>1.0017</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>124_755</td>\n      <td>124</td>\n      <td>755</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":4},{"id":"5b16186e","cell_type":"markdown","source":"## 4) Building the trip table from all week files\n\nIf there are many files, this may take some time. The upside is that you’ll keep a compact trip-level table in RAM, rather than the full time-series data.","metadata":{}},{"id":"c5b7f757","cell_type":"code","source":"trip_tables = []\nfor i, f in enumerate(week_files):\n    tdf = aggregate_week_file(f)\n    trip_tables.append(tdf)\n    if (i+1) % 5 == 0:\n        print(f\"Processed {i+1}/{len(week_files)} files. trips so far: {sum(len(x) for x in trip_tables)}\")\n\ntrips_df = pd.concat(trip_tables, ignore_index=True)\n\n# чистим NaN по таргету/дистанции\ntrips_df = trips_df.dropna(subset=[\"energy_per_km\"])\ntrips_df = trips_df[trips_df[\"distance_km\"] > 0.1].reset_index(drop=True)\n\nprint(\"Trips:\", trips_df.shape)\ntrips_df.describe(include=\"all\").T.head(15)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-14T17:52:55.591021Z","iopub.execute_input":"2026-02-14T17:52:55.591365Z","iopub.status.idle":"2026-02-14T17:54:54.064942Z","shell.execute_reply.started":"2026-02-14T17:52:55.591337Z","shell.execute_reply":"2026-02-14T17:54:54.064112Z"}},"outputs":[{"name":"stdout","text":"Processed 5/54 files. trips so far: 4172\nProcessed 10/54 files. trips so far: 7715\nProcessed 15/54 files. trips so far: 11284\nProcessed 20/54 files. trips so far: 14144\nProcessed 25/54 files. trips so far: 17367\nProcessed 30/54 files. trips so far: 20413\nProcessed 35/54 files. trips so far: 23322\nProcessed 40/54 files. trips so far: 26008\nProcessed 45/54 files. trips so far: 28293\nProcessed 50/54 files. trips so far: 30758\nTrips: (32512, 14)\n","output_type":"stream"},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"                   count unique       top freq      mean       std      min  \\\nduration_min  32512.0000    NaN       NaN  NaN    8.9442    8.4151   0.1550   \ndistance_km   32512.0000    NaN       NaN  NaN    5.4583    6.4761   0.1003   \nspeed_mean    32512.0000    NaN       NaN  NaN   38.6670   14.8794   0.3198   \nspeed_var     32512.0000    NaN       NaN  NaN  553.7276  320.3532   0.0000   \naccel_mean    32512.0000    NaN       NaN  NaN   -0.0030    0.0338  -0.2976   \naccel_var     32512.0000    NaN       NaN  NaN    1.6189    0.9294   0.0000   \naccel_p95     32512.0000    NaN       NaN  NaN    2.0597    0.8500   0.0000   \nstop_go_ratio 32512.0000    NaN       NaN  NaN    0.1301    0.1098   0.0000   \nidle_time_min 32512.0000    NaN       NaN  NaN    2.0247    3.6793   0.0000   \nenergy_kWh    32512.0000    NaN       NaN  NaN   -0.0359    0.7795 -28.7004   \nenergy_per_km 32512.0000    NaN       NaN  NaN   -0.0057    0.0969  -1.5368   \ntrip_id            32512  32512  574_1298    1       NaN       NaN      NaN   \nVehId         32512.0000    NaN       NaN  NaN  387.7981  144.5916   2.0000   \nTrip          32512.0000    NaN       NaN  NaN 1546.1277 1131.4399   2.0000   \n\n                   25%       50%       75%        max  \nduration_min    3.5983    6.8817   11.4667   168.6817  \ndistance_km     2.1223    4.2541    6.8474   224.4132  \nspeed_mean     29.1719   36.6592   45.7210   115.9534  \nspeed_var     351.2364  521.3446  681.8790  3019.8586  \naccel_mean     -0.0141   -0.0014    0.0088     0.4041  \naccel_var       1.0137    1.4435    1.9970    17.6734  \naccel_p95       1.3889    1.8519    2.7778    13.0556  \nstop_go_ratio   0.0471    0.1077    0.1900     0.9556  \nidle_time_min   0.3400    1.1267    2.4350   161.3533  \nenergy_kWh      0.0000    0.0000    0.0000    71.3665  \nenergy_per_km   0.0000    0.0000    0.0000     2.2359  \ntrip_id            NaN       NaN       NaN        NaN  \nVehId         276.0000  410.0000  501.0000   630.0000  \nTrip          915.0000 1352.0000 1900.0000 11580.0000  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>count</th>\n      <th>unique</th>\n      <th>top</th>\n      <th>freq</th>\n      <th>mean</th>\n      <th>std</th>\n      <th>min</th>\n      <th>25%</th>\n      <th>50%</th>\n      <th>75%</th>\n      <th>max</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>duration_min</th>\n      <td>32512.0000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>8.9442</td>\n      <td>8.4151</td>\n      <td>0.1550</td>\n      <td>3.5983</td>\n      <td>6.8817</td>\n      <td>11.4667</td>\n      <td>168.6817</td>\n    </tr>\n    <tr>\n      <th>distance_km</th>\n      <td>32512.0000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>5.4583</td>\n      <td>6.4761</td>\n      <td>0.1003</td>\n      <td>2.1223</td>\n      <td>4.2541</td>\n      <td>6.8474</td>\n      <td>224.4132</td>\n    </tr>\n    <tr>\n      <th>speed_mean</th>\n      <td>32512.0000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>38.6670</td>\n      <td>14.8794</td>\n      <td>0.3198</td>\n      <td>29.1719</td>\n      <td>36.6592</td>\n      <td>45.7210</td>\n      <td>115.9534</td>\n    </tr>\n    <tr>\n      <th>speed_var</th>\n      <td>32512.0000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>553.7276</td>\n      <td>320.3532</td>\n      <td>0.0000</td>\n      <td>351.2364</td>\n      <td>521.3446</td>\n      <td>681.8790</td>\n      <td>3019.8586</td>\n    </tr>\n    <tr>\n      <th>accel_mean</th>\n      <td>32512.0000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>-0.0030</td>\n      <td>0.0338</td>\n      <td>-0.2976</td>\n      <td>-0.0141</td>\n      <td>-0.0014</td>\n      <td>0.0088</td>\n      <td>0.4041</td>\n    </tr>\n    <tr>\n      <th>accel_var</th>\n      <td>32512.0000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.6189</td>\n      <td>0.9294</td>\n      <td>0.0000</td>\n      <td>1.0137</td>\n      <td>1.4435</td>\n      <td>1.9970</td>\n      <td>17.6734</td>\n    </tr>\n    <tr>\n      <th>accel_p95</th>\n      <td>32512.0000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2.0597</td>\n      <td>0.8500</td>\n      <td>0.0000</td>\n      <td>1.3889</td>\n      <td>1.8519</td>\n      <td>2.7778</td>\n      <td>13.0556</td>\n    </tr>\n    <tr>\n      <th>stop_go_ratio</th>\n      <td>32512.0000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.1301</td>\n      <td>0.1098</td>\n      <td>0.0000</td>\n      <td>0.0471</td>\n      <td>0.1077</td>\n      <td>0.1900</td>\n      <td>0.9556</td>\n    </tr>\n    <tr>\n      <th>idle_time_min</th>\n      <td>32512.0000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2.0247</td>\n      <td>3.6793</td>\n      <td>0.0000</td>\n      <td>0.3400</td>\n      <td>1.1267</td>\n      <td>2.4350</td>\n      <td>161.3533</td>\n    </tr>\n    <tr>\n      <th>energy_kWh</th>\n      <td>32512.0000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>-0.0359</td>\n      <td>0.7795</td>\n      <td>-28.7004</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>71.3665</td>\n    </tr>\n    <tr>\n      <th>energy_per_km</th>\n      <td>32512.0000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>-0.0057</td>\n      <td>0.0969</td>\n      <td>-1.5368</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>2.2359</td>\n    </tr>\n    <tr>\n      <th>trip_id</th>\n      <td>32512</td>\n      <td>32512</td>\n      <td>574_1298</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>VehId</th>\n      <td>32512.0000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>387.7981</td>\n      <td>144.5916</td>\n      <td>2.0000</td>\n      <td>276.0000</td>\n      <td>410.0000</td>\n      <td>501.0000</td>\n      <td>630.0000</td>\n    </tr>\n    <tr>\n      <th>Trip</th>\n      <td>32512.0000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1546.1277</td>\n      <td>1131.4399</td>\n      <td>2.0000</td>\n      <td>915.0000</td>\n      <td>1352.0000</td>\n      <td>1900.0000</td>\n      <td>11580.0000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":5},{"id":"b0c5f327","cell_type":"markdown","source":"## 5) Merging static tables (weight/type/class)\n\nThe static data are stored in two XLSX files. We merge them by `VehId` and add `Generalized_Weight` as an important static feature.","metadata":{}},{"id":"30320bd9","cell_type":"code","source":"def load_static_tables(phev_ev_path: Path, ice_hev_path: Path) -> pd.DataFrame:\n    phev = pd.read_excel(phev_ev_path)\n    ice = pd.read_excel(ice_hev_path)\n\n    # унифицируем колонку типа двигателя\n    phev = phev.rename(columns={\"EngineType\": \"VehicleType\"})\n    ice = ice.rename(columns={\"Vehicle Type\": \"VehicleType\"})\n\n    static = pd.concat([phev, ice], ignore_index=True)\n    # dedupe in case of overlaps\n    static = static.drop_duplicates(subset=[\"VehId\"]).reset_index(drop=True)\n    return static\n\nstatic_df = load_static_tables(STATIC_PHEV_EV_XLSX, STATIC_ICE_HEV_XLSX)\ntrips_df = trips_df.merge(static_df, on=\"VehId\", how=\"left\")\ntrips_df[\"Generalized_Weight\"] = pd.to_numeric(trips_df[\"Generalized_Weight\"], errors=\"coerce\")\n\ntrips_df[[\"VehId\",\"VehicleType\",\"Vehicle Class\",\"Generalized_Weight\"]].head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-14T18:00:37.743952Z","iopub.execute_input":"2026-02-14T18:00:37.744247Z","iopub.status.idle":"2026-02-14T18:00:37.817335Z","shell.execute_reply.started":"2026-02-14T18:00:37.744222Z","shell.execute_reply":"2026-02-14T18:00:37.816752Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"   VehId VehicleType Vehicle Class  Generalized_Weight\n0      8         ICE           Car           2500.0000\n1      8         ICE           Car           2500.0000\n2     10          EV           Car           3500.0000\n3     11        PHEV           Car           4000.0000\n4    124         HEV       NO DATA           3000.0000","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>VehId</th>\n      <th>VehicleType</th>\n      <th>Vehicle Class</th>\n      <th>Generalized_Weight</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>8</td>\n      <td>ICE</td>\n      <td>Car</td>\n      <td>2500.0000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>8</td>\n      <td>ICE</td>\n      <td>Car</td>\n      <td>2500.0000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>10</td>\n      <td>EV</td>\n      <td>Car</td>\n      <td>3500.0000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>11</td>\n      <td>PHEV</td>\n      <td>Car</td>\n      <td>4000.0000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>124</td>\n      <td>HEV</td>\n      <td>NO DATA</td>\n      <td>3000.0000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":11},{"id":"f5bbb451","cell_type":"markdown","source":"## 6) Train/Val/Test split by `VehId` (no leakage)\n\nTo prevent the model from memorizing a specific vehicle, we split the data by `VehId`.","metadata":{}},{"id":"511f440f","cell_type":"code","source":"def split_by_vehicle(trips: pd.DataFrame, test_size=0.2, val_size=0.2, seed=42):\n    vehicles = trips[\"VehId\"].unique()\n    train_val, test = train_test_split(vehicles, test_size=test_size, random_state=seed)\n    train, val = train_test_split(train_val, test_size=val_size/(1-test_size), random_state=seed)\n    return (\n        trips[\"VehId\"].isin(train),\n        trips[\"VehId\"].isin(val),\n        trips[\"VehId\"].isin(test),\n    )\n\ntrain_mask, val_mask, test_mask = split_by_vehicle(trips_df, seed=RANDOM_STATE)\ntrain_df, val_df, test_df = trips_df[train_mask], trips_df[val_mask], trips_df[test_mask]\nlen(train_df), len(val_df), len(test_df)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-14T18:00:44.033123Z","iopub.execute_input":"2026-02-14T18:00:44.033725Z","iopub.status.idle":"2026-02-14T18:00:44.054192Z","shell.execute_reply.started":"2026-02-14T18:00:44.033700Z","shell.execute_reply":"2026-02-14T18:00:44.053653Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"(20080, 6137, 6295)"},"metadata":{}}],"execution_count":12},{"id":"6ccd91ce","cell_type":"markdown","source":"## 7) Training an XGBoost regressor + saving the model\n\nWe use numerical features, and optionally one-hot encode categorical features (e.g., `VehicleType`, `Class`, `Drive Wheels`). Here we apply one-hot encoding via `pandas.get_dummies`.\n\nResult: we save the trained model and the `residuals.parquet` table.","metadata":{}},{"id":"7397ccd1","cell_type":"code","source":"TARGET = \"energy_per_km\"\nID_COLS = [\"trip_id\", \"VehId\", \"Trip\"]\n\n# выберем базовый набор численных\nbase_num_features = [\n    \"duration_min\",\"distance_km\",\"speed_mean\",\"speed_var\",\n    \"accel_mean\",\"accel_var\",\"accel_p95\",\n    \"stop_go_ratio\",\"idle_time_min\",\n    \"Generalized_Weight\",\n]\n\n# категориальные\ncat_features = [\"VehicleType\",\"Vehicle Class\",\"Transmission\",\"Drive Wheels\"]\n\ndef make_design(df: pd.DataFrame) -> pd.DataFrame:\n    X = df[base_num_features + cat_features].copy()\n    X = pd.get_dummies(X, columns=cat_features, dummy_na=True)\n    return X\n\nX_train = make_design(train_df)\nX_val   = make_design(val_df)\nX_test  = make_design(test_df)\n\n# общий список колонок (union)\nall_cols = sorted(set(X_train.columns) | set(X_val.columns) | set(X_test.columns))\n\n# одинаковые колонки + одинаковый порядок\nX_train = X_train.reindex(columns=all_cols, fill_value=0.0)\nX_val   = X_val.reindex(columns=all_cols, fill_value=0.0)\nX_test  = X_test.reindex(columns=all_cols, fill_value=0.0)\n\nprint(X_train.shape, X_val.shape, X_test.shape)  # должны совпасть по числу фич\n\nmodel = XGBRegressor(\n    n_estimators=2000,\n    learning_rate=0.03,\n    max_depth=6,\n    subsample=0.8,\n    colsample_bytree=0.8,\n    reg_alpha=0.0,\n    reg_lambda=1.0,\n    random_state=RANDOM_STATE,\n    tree_method=\"hist\",\n    n_jobs=-1,\n    early_stopping_rounds=50,\n    eval_metric=\"rmse\"\n)\n\nmodel.fit(\n    X_train, y_train,\n    eval_set=[(X_val, y_val)],\n    verbose=50\n)\n\ndef eval_split(name, X, y):\n    pred = model.predict(X)\n    mae = mean_absolute_error(y, pred)\n    rmse = np.sqrt(mean_squared_error(y, pred))\n    print(f\"{name}: MAE={mae:.4f}, RMSE={rmse:.4f}\")\n    return pred\n\n_ = eval_split(\"VAL\", X_val, y_val)\n_ = eval_split(\"TEST\", X_test, y_test)\n\n# save model + feature columns\nmodel_path = MODEL_DIR / \"xgb_energy_regressor.joblib\"\njoblib.dump({\"model\": model, \"feature_columns\": list(X_train.columns)}, model_path)\nprint(\"Saved:\", model_path)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-14T18:45:09.572133Z","iopub.execute_input":"2026-02-14T18:45:09.572462Z","iopub.status.idle":"2026-02-14T18:45:09.957704Z","shell.execute_reply.started":"2026-02-14T18:45:09.572436Z","shell.execute_reply":"2026-02-14T18:45:09.957144Z"}},"outputs":[{"name":"stdout","text":"(20080, 41) (6137, 41) (6295, 41)\n[0]\tvalidation_0-rmse:0.06676\n[50]\tvalidation_0-rmse:0.06729\n[62]\tvalidation_0-rmse:0.06801\nVAL: MAE=0.0171, RMSE=0.0634\nTEST: MAE=0.0233, RMSE=0.0815\nSaved: models/xgb_energy_regressor.joblib\n","output_type":"stream"}],"execution_count":15},{"id":"9f424e4f","cell_type":"markdown","source":"## 8) Residuals table (`actual`, `predicted`, `residual`)","metadata":{}},{"id":"69937cc1","cell_type":"code","source":"# predict for all trips\nX_all = make_design(trips_df)\nX_all = X_all.reindex(columns=list(X_train.columns), fill_value=0.0)\n\npayload = joblib.load(model_path)\nmdl = payload[\"model\"]\n\npred_all = mdl.predict(X_all)\nres_df = trips_df[ID_COLS + [TARGET]].copy()\nres_df[\"predicted_energy_per_km\"] = pred_all\nres_df[\"residual\"] = res_df[TARGET] - res_df[\"predicted_energy_per_km\"]\n\nout_path = OUT_DIR / \"residuals.parquet\"\nres_df.to_parquet(out_path, index=False)\nprint(\"Saved residuals:\", out_path)\n\nres_df.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-14T18:46:51.641761Z","iopub.execute_input":"2026-02-14T18:46:51.642093Z","iopub.status.idle":"2026-02-14T18:46:51.791711Z","shell.execute_reply.started":"2026-02-14T18:46:51.642055Z","shell.execute_reply":"2026-02-14T18:46:51.791122Z"}},"outputs":[{"name":"stdout","text":"Saved residuals: outputs/residuals.parquet\n","output_type":"stream"},{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"   trip_id  VehId  Trip  energy_per_km  predicted_energy_per_km  residual\n0    8_706      8   706         0.0000                  -0.0067    0.0067\n1    8_707      8   707         0.0000                  -0.0067    0.0067\n2  10_1558     10  1558        -0.0704                  -0.0399   -0.0305\n3  11_1485     11  1485        -0.0052                  -0.0482    0.0429\n4  124_755    124   755         0.0000                  -0.0029    0.0029","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>trip_id</th>\n      <th>VehId</th>\n      <th>Trip</th>\n      <th>energy_per_km</th>\n      <th>predicted_energy_per_km</th>\n      <th>residual</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>8_706</td>\n      <td>8</td>\n      <td>706</td>\n      <td>0.0000</td>\n      <td>-0.0067</td>\n      <td>0.0067</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>8_707</td>\n      <td>8</td>\n      <td>707</td>\n      <td>0.0000</td>\n      <td>-0.0067</td>\n      <td>0.0067</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>10_1558</td>\n      <td>10</td>\n      <td>1558</td>\n      <td>-0.0704</td>\n      <td>-0.0399</td>\n      <td>-0.0305</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>11_1485</td>\n      <td>11</td>\n      <td>1485</td>\n      <td>-0.0052</td>\n      <td>-0.0482</td>\n      <td>0.0429</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>124_755</td>\n      <td>124</td>\n      <td>755</td>\n      <td>0.0000</td>\n      <td>-0.0029</td>\n      <td>0.0029</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":16},{"id":"2f09de01-e9e5-41b0-8797-4ffd156a6bf6","cell_type":"markdown","source":"## 9) Saving model","metadata":{}},{"id":"1db87dd7-9d9a-401d-8093-cf1612ccf581","cell_type":"code","source":"import joblib\nimport numpy as np\nfrom pathlib import Path\n\nARTIFACT_DIR = Path(\"models\")\nARTIFACT_DIR.mkdir(parents=True, exist_ok=True)\n\nfeature_columns = list(X_train.columns)\n\nartifact = {\n    \"model\": model,\n    \"feature_columns\": feature_columns,\n    # чтобы потом гарантированно делать fillna одинаково\n    \"feature_medians\": X_train.median(numeric_only=True).to_dict(),\n    # background для LIME (не обязательно, но удобно)\n    \"lime_background\": X_train.sample(n=min(5000, len(X_train)), random_state=RANDOM_STATE).astype(float),\n}\n\njoblib.dump(artifact, ARTIFACT_DIR / \"xgb_energy_artifact.joblib\")\nprint(\"Saved:\", ARTIFACT_DIR / \"xgb_energy_artifact.joblib\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-14T18:49:31.908980Z","iopub.execute_input":"2026-02-14T18:49:31.909310Z","iopub.status.idle":"2026-02-14T18:49:31.929308Z","shell.execute_reply.started":"2026-02-14T18:49:31.909286Z","shell.execute_reply":"2026-02-14T18:49:31.928831Z"}},"outputs":[{"name":"stdout","text":"Saved: models/xgb_energy_artifact.joblib\n","output_type":"stream"}],"execution_count":17},{"id":"92facdc6-a5b4-4761-a324-60fb0cf02877","cell_type":"markdown","source":"## 10) Load the model","metadata":{}},{"id":"b7906159-d02d-4663-b726-a2d8b2083c1d","cell_type":"code","source":"import joblib\nimport pandas as pd\n\nartifact = joblib.load(\"models/xgb_energy_artifact.joblib\")\nmodel = artifact[\"model\"]\nfeature_columns = artifact[\"feature_columns\"]\nfeature_medians = artifact[\"feature_medians\"]\n\ndef predict_from_raw_design(X_design: pd.DataFrame) -> pd.Series:\n    # 1) привести к тем же колонкам и порядку\n    X = X_design.reindex(columns=feature_columns, fill_value=0.0)\n    # 2) fillna теми же медианами\n    for c, m in feature_medians.items():\n        if c in X.columns:\n            X[c] = X[c].fillna(m)\n    return pd.Series(model.predict(X), index=X_design.index)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-14T18:49:38.280835Z","iopub.execute_input":"2026-02-14T18:49:38.281131Z","iopub.status.idle":"2026-02-14T18:49:38.290659Z","shell.execute_reply.started":"2026-02-14T18:49:38.281107Z","shell.execute_reply":"2026-02-14T18:49:38.290146Z"}},"outputs":[],"execution_count":18},{"id":"e36a364a-9ee2-4924-8127-fa31b1986b1b","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}